{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2042,
     "status": "ok",
     "timestamp": 1639968378873,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "UYpJjc9j6FKL",
    "outputId": "c30fac9e-7c56-4e04-e481-faa34e914343"
   },
   "outputs": [],
   "source": [
    "import warnings, pickle, math, random, numpy, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from deap import creator, base, tools, algorithms, GA\n",
    "from scoop import futures\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list contains all the eeg channels used in Deap dataset \n",
    "subject_names = ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', 's11', 's12', \n",
    "                 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21',\n",
    "                 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30', 's31', 's32']\n",
    "eeg_channels = np.array(['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', \n",
    "                         'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', \n",
    "                         'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFitness(individual):\n",
    "    global x_train, x_test, y_train, y_test\n",
    "    total_features = int(x.shape[1])\n",
    "    all_features_name = list(x.columns)\n",
    "    if(len(set(individual)) == 1 and list(set(individual))[0] == 0):\n",
    "        # If all gene values are 0 then return 0\n",
    "        return 0\n",
    "    features = []\n",
    "    for i in range(0, len(individual)):\n",
    "        if(individual[i]==1):\n",
    "            features.append(all_features_name[i])\n",
    "    no_sel_features = len(features)\n",
    "    _classifier = SVC(kernel = 'poly')\n",
    "    new_x_train = x_train[features].copy()\n",
    "    new_x_test = x_test[features].copy()\n",
    "    _classifier.fit(new_x_train, y_train)\n",
    "    predictions = _classifier.predict(new_x_test)\n",
    "    accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
    "    my_fitness = alpha*accuracy + (1-alpha)*((total_features - no_sel_features)/total_features)\n",
    "    return (my_fitness,)\n",
    "def get_final_report(individual):\n",
    "    total_features = int(x.shape[1])\n",
    "    all_features_name = list(x.columns)\n",
    "    if(len(set(individual)) == 1 and list(set(individual))[0] == 0):\n",
    "        # If all gene values are 0 then return 0\n",
    "        return 0, 0, 0, 0\n",
    "    features = []\n",
    "    for i in range(0, len(individual)):\n",
    "        if(individual[i]==1):\n",
    "            features.append(all_features_name[i])\n",
    "    no_sel_features = len(features)\n",
    "    _classifier = SVC(kernel = 'poly')\n",
    "    new_x_train = x_train[features].copy()\n",
    "    new_x_test = x_test[features].copy()\n",
    "    _classifier.fit(new_x_train, y_train)\n",
    "    predictions = _classifier.predict(new_x_test)\n",
    "    accuracy = accuracy_score(y_true = y_test, y_pred = predictions)\n",
    "    prec = precision_score(predictions, y_test)\n",
    "    recall = recall_score(predictions, y_test)\n",
    "    f1 = f1_score(predictions, y_test)\n",
    "    return accuracy, prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1639968416723,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "cS0m53fZ7LhK"
   },
   "outputs": [],
   "source": [
    "def kfold(x, y):\n",
    "    # do the scalling\n",
    "    names = x.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x = pd.DataFrame(x, columns=names)\n",
    "    feature_vectors = list(x.columns)\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    skf.get_n_splits(x, y)\n",
    "    test_data, train_data, train_label, test_label = [], [], [], []\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # convert into dataframe\n",
    "        X_train = pd.DataFrame.from_records(X_train)\n",
    "        X_train.columns = feature_vectors\n",
    "        X_test = pd.DataFrame.from_records(X_test)\n",
    "        X_test.columns = feature_vectors\n",
    "        train_data.append(X_train)\n",
    "        test_data.append(X_test)\n",
    "        train_label.append(y_train)\n",
    "        test_label.append(y_test)\n",
    "    return train_data, test_data, train_label, test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1639968416725,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "BtVNGpokANb_"
   },
   "outputs": [],
   "source": [
    "def getHof(popu):\n",
    "    global toolbox\n",
    "    pop = popu\n",
    "    hof = tools.HallOfFame(numPop * numGen)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", numpy.mean)\n",
    "    stats.register(\"std\", numpy.std)\n",
    "    stats.register(\"min\", numpy.min)\n",
    "    stats.register(\"max\", numpy.max)\n",
    "\n",
    "    # Launch genetic algorithm, change the crossover and mutation probability\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb = 0.65, mutpb = 0.3,\\\n",
    "                                   ngen=numGen, stats=stats, halloffame=hof, verbose=False)\n",
    "    return hof, log # Return the hall of fame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_list(best_individual):\n",
    "    channel_list = []\n",
    "    eeg_channels = np.array(optimal_channels)\n",
    "    for i in range(0, len(best_individual)):\n",
    "        if(best_individual[i]==1):\n",
    "            # add that channel in the optimal set of channels\n",
    "            channel_list.append(optimal_channels[i])\n",
    "    return channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drive_code(inputdata, inputlabel, numPop, numGen):\n",
    "    global toolbox, x, x_train, x_test, y_train, y_test\n",
    "    #========================         Data opening       ==============================\n",
    "    data = inputdata.copy()\n",
    "    features_name = data.columns\n",
    "    total_features = len(data.columns)-1\n",
    "    x, y = data[data.columns[:total_features]], inputlabel.copy()\n",
    "    \n",
    "    # drop constant features\n",
    "    x = x.loc[:,x.apply(pd.Series.nunique) != 1]\n",
    "    \n",
    "    #============================      Train-Test splitting      ======================\n",
    "    x, y = shuffle(x, y, random_state = 40)\n",
    "    train_data, test_data, train_label, test_label = kfold(x.copy(), y.copy())\n",
    "    #==================================================================================\n",
    "    \n",
    "    \n",
    "    creator.create('FitnessMax', base.Fitness, weights = (1.0,))\n",
    "    creator.create('Individual', list, fitness = creator.FitnessMax)\n",
    "    toolbox = base.Toolbox() # Create Toolbox\n",
    "    toolbox.register('attr_bool', random.randint, 0, 1)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_bool, int(x.shape[1]))\n",
    "    toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "    initial_population = toolbox.population(numPop)\n",
    "    \n",
    "    #=============================     GA based feature selection  ==================\n",
    "    toolbox.register('evaluate', getFitness)\n",
    "    toolbox.register('mate', tools.cxOnePoint)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.1)\n",
    "    toolbox.register('select', tools.selTournament, tournsize = 7)\n",
    "    # taing optimal channels\n",
    "    acc_cross, prec_cross, recall_cross, f1_score_cross = [], [], [], []\n",
    "    print('Accuracy\\tPre\\tRecall\\tF1')\n",
    "    for i in range(0, 10):\n",
    "        x_train, x_test, y_train, y_test = train_data[i], test_data[i], train_label[i], test_label[i]\n",
    "        initial_population = toolbox.population(numPop)\n",
    "        hof, log = getHof(initial_population)\n",
    "        best_individual = list(hof)[0]\n",
    "        acc, prec, recall, f1_score = get_final_report(best_individual)\n",
    "        acc_cross.append(acc)\n",
    "        prec_cross.append(prec)\n",
    "        recall_cross.append(recall)\n",
    "        f1_score_cross.append(f1_score)\n",
    "        print(float('{:.3f}'.format(acc)), '\\t\\t', float('{:.3f}'.format(prec)), '\\t', float('{:.3f}'.format(recall)),\n",
    "                    '\\t', float('{:.3f}'.format(f1_score)))\n",
    "    acc_cross, prec_cross = np.array(acc_cross), np.array(prec_cross)\n",
    "    recall_cross, f1_score_cross = np.array(recall_cross), np.array(f1_score_cross)\n",
    "    acc_mean, prec_mean = np.mean(acc_cross), np.mean(prec_cross)\n",
    "    recall_mean, f1_mean = np.mean(recall_cross), np.mean(f1_score_cross)\n",
    "    print('-'*43)\n",
    "    print(float('{:.3f}'.format(acc_mean)), '\\t\\t', float('{:.3f}'.format(prec_mean)), '\\t', float('{:.3f}'.format(recall_mean)), '\\t', float('{:.3f}'.format(f1_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_arousal_channels = [['P7', 'Fp2', 'AF4', 'F8', 'Fp1']\n",
    ",['P7', 'F3', 'FC2', 'Pz', 'C4', 'CP2', 'T8', 'P3', 'FC5', 'F8', 'P4', 'CP5', 'CP1', 'O2', 'FC6', 'Cz', 'PO3', 'P8', 'O1', 'CP6', 'AF4', 'Oz', 'F4']\n",
    ",['AF4', 'Fp1']\n",
    ",['T8', 'FC2', 'Fz', 'Pz', 'CP6', 'P3']\n",
    ",['PO3', 'Pz', 'P3', 'CP5', 'C3', 'Fp2', 'FC5', 'PO4', 'T7', 'F8', 'FC2', 'FC6']\n",
    ",['C3', 'F3', 'AF4', 'AF3', 'FC2', 'F4', 'T8', 'Oz', 'FC5', 'F7', 'FC1', 'Cz', 'Fp2', 'O2', 'PO3', 'CP6', 'PO4']\n",
    ",['FC1', 'O1', 'FC5', 'PO3', 'P7', 'Fp2', 'CP1', 'CP6', 'Cz']\n",
    ",['Fz', 'AF4', 'C4', 'AF3', 'F4', 'FC1', 'Fp1', 'CP1', 'O1', 'P4', 'F3']\n",
    ",['AF4', 'Oz', 'T8', 'T7', 'P8', 'AF3', 'Fp1', 'Fz', 'Pz', 'P3', 'CP6', 'CP1', 'FC2', 'CP2', 'P7', 'FC6', 'P4', 'CP5', 'F3', 'PO4', 'FC5', 'O2']\n",
    ",['PO4', 'Fz']\n",
    ",['P4', 'Fz', 'Pz', 'P8', 'Oz', 'O2', 'PO3', 'F4', 'C3', 'PO4', 'O1', 'Cz', 'T8', 'C4', 'CP1', 'CP6', 'AF4', 'F7', 'CP2', 'P3', 'F8', 'FC1', 'F3', 'P7', 'FC5', 'FC2', 'FC6', 'Fp2', 'Fp1']\n",
    ",['FC6', 'F7', 'CP5', 'FC5']\n",
    ",['T8', 'CP1', 'P3', 'C4']\n",
    ",['AF3', 'Oz', 'FC1', 'Fp1', 'F8', 'C4', 'AF4', 'PO3']\n",
    ",['FC1', 'P3', 'FC2', 'CP6', 'P8', 'O1', 'C3', 'C4']\n",
    ",['O2', 'FC1', 'P8', 'Fz', 'Cz']\n",
    ",['P4', 'Pz', 'PO4', 'O1', 'PO3', 'C4', 'C3']\n",
    ",['FC5', 'AF4', 'C4', 'PO3']\n",
    ",['CP5', 'F8', 'P8', 'Oz', 'O2', 'CP6']\n",
    ",['Fp1', 'P7', 'F3', 'AF3', 'F8', 'FC5', 'CP5', 'AF4', 'T7', 'C3']\n",
    ",['P7', 'AF3']\n",
    ",['Oz', 'AF3', 'FC2', 'FC1']\n",
    ",['Fp2', 'C3', 'CP5', 'CP2', 'FC2', 'FC5', 'P4', 'AF4', 'T8']\n",
    ",['O2', 'P8', 'CP2', 'CP1', 'PO3', 'FC5', 'Cz', 'FC2', 'C3', 'PO4', 'FC1', 'P7', 'T7']\n",
    ",['F8', 'C4', 'PO3', 'FC5', 'AF4', 'F4', 'CP2', 'T7', 'Fp1', 'C3', 'AF3', 'Oz', 'P8', 'FC2', 'PO4', 'FC6']\n",
    ",['CP5', 'AF4', 'F7', 'Oz', 'FC2', 'AF3', 'Cz', 'F4', 'P4', 'P3', 'PO4']\n",
    ",['Oz', 'O2', 'Pz', 'CP1', 'FC5', 'AF4', 'F8', 'CP5', 'FC2', 'P4', 'Cz', 'F4', 'Fp1']\n",
    ",['PO3', 'F4', 'FC6', 'C4', 'Cz', 'CP1', 'CP5', 'C3']\n",
    ",['PO4', 'P4', 'O2', 'FC2', 'F8', 'Cz', 'C4', 'CP2', 'Pz']\n",
    ",['PO4', 'Fz', 'P3', 'AF3', 'P4', 'FC2', 'CP1', 'FC6', 'Pz', 'F3', 'CP2', 'CP5', 'C4', 'FC5', 'P8', 'Fp2', 'CP6', 'T7', 'T8', 'F4', 'Fp1', 'O2', 'AF4']\n",
    ",['C4', 'PO4']\n",
    ",['Cz', 'AF4', 'F3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(sub):\n",
    "    fs_vector = []\n",
    "    mypath = '/Users/shyammarjit/Desktop/Brain Computer Interface/Hybrid Sequential Forward channel selection (HSFCS)/Subject Independent/data files/'\n",
    "    datapath = mypath + sub + '_arousal.csv'\n",
    "    data = pd.read_csv(datapath)\n",
    "    label = data[data.columns[-1]]\n",
    "    optimal_arousal_channels = subject_arousal_channels[subject_names.index(sub)]\n",
    "    features_list = ['theta_mean', 'theta_var', 'theta_mode', 'theta_median', 'theta_skew', 'theta_std', 'theta_kurtosis', \n",
    "                   'theta_f_d', 'theta_nfd', 'theta_s_d', 'theta_nsd', 'alpha_mean', 'alpha_var', 'alpha_mode', 'alpha_median',\n",
    "                   'alpha_skew', 'alpha_std', 'alpha_kurtosis', 'alpha_f_d', 'alpha_nfd', 'alpha_s_d', 'alpha_nsd',\n",
    "                   'beta_mean', 'beta_var', 'beta_mode', 'beta_median', 'beta_skew', 'beta_std', 'beta_kurtosis', \n",
    "                   'beta_f_d', 'beta_nfd', 'beta_s_d', 'beta_nsd', 'gamma_mean', 'gamma_var', 'gamma_mode', 'gamma_median',\n",
    "                   'gamma_skew', 'gamma_std', 'gamma_kurtosis', 'gamma_f_d', 'gamma_nfd', 'gamma_s_d', 'gamma_nsd', 'theta_energy',\n",
    "                   'alpha_energy', 'beta_energy', 'gamma_energy', 'theta_avg_power', 'alpha_avg_power', 'beta_avg_power',\n",
    "                   'gamma_avg_power', 'theta_rms', 'alpha_rms', 'beta_rms', 'gamma_rms',\n",
    "                   'theta_ShEn', 'alpha_ShEn', 'beta_ShEn', 'gamma_ShEn', 'theta_aentropy', 'alpha_aentropy',\n",
    "                   'beta_aentropy', 'gamma_aentropy', 'theta_pentropy', 'alpha_pentropy', 'beta_pentropy', 'gamma_pentropy', \n",
    "                   'theta_wpe', 'alpha_wpe', 'theta_wpe', 'gamma_wpe', 'H_theta', 'c_theta', 'H_alpha', 'c_alpha', 'H_beta',\n",
    "                   'c_beta', 'H_gamma', 'c_gamma', 'higuchi_theta', 'petrosian_theta', 'higuchi_alpha', 'petrosian_alpha', 'higuchi_beta',\n",
    "                   'petrosian_beta', 'higuchi_gamma', 'petrosian_gamma', 'aic_theta_ar',\n",
    "                   'hqic_theta_ar', 'bic_theta_ar', 'llf_theta_ar', 'aic_alpha_ar', 'hqic_alpha_ar', 'bic_alpha_ar', 'llf_alpha_ar', \n",
    "                   'aic_beta_ar', 'hqic_beta_ar', 'bic_beta_ar', 'llf_beta_ar', 'aic_gamma_ar', 'hqic_gamma_ar', 'bic_gamma_ar', \n",
    "                   'llf_gamma_ar', 'aic_theta_arma', 'hqic_theta_arma', 'bic_theta_arma', 'llf_theta_arma', 'aic_alpha_arma', \n",
    "                   'hqic_alpha_arma', 'bic_alpha_arma', 'llf_alpha_arma', 'aic_beta_arma', 'hqic_beta_arma', 'bic_beta_arma', \n",
    "                   'llf_beta_arma', 'aic_gamma_arma', 'hqic_gamma_arma', 'bic_gamma_arma', 'llf_gamma_arma']\n",
    "    for i in optimal_arousal_channels:\n",
    "        for j in features_list:\n",
    "            fs_vector.append(i + '_' + j)\n",
    "    data = data[fs_vector]\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "                                              s32                                              \n",
      "================================================================================================= \n",
      "\n",
      "Accuracy\tPre\tRecall\tF1\n",
      "0.5 \t\t 0.5 \t 0.5 \t 0.5\n",
      "0.5 \t\t 1.0 \t 0.5 \t 0.667\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "0.75 \t\t 0.667 \t 1.0 \t 0.8\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
      "-------------------------------------------\n",
      "0.875 \t\t 0.917 \t 0.9 \t 0.897\n"
     ]
    }
   ],
   "source": [
    "#=======================        Hyperparameters value      =========================\n",
    "alpha = 0.90\n",
    "numPop, numGen = 100, 50\n",
    "#===================================================================================\n",
    "\n",
    "for sub in subject_names[31:32]:\n",
    "    indepdata, label = getData(sub)\n",
    "    print('='*97)\n",
    "    print(\" \"*45, sub, \" \"*45)\n",
    "    print('='*97,\"\\n\")\n",
    "    drive_code(indepdata, label, numPop, numGen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n=================================================================================================\\n                                              s01                                              \\n================================================================================================= \\n\\nAccuracy\\tPre\\tRecall\\tF1\\n0.75 \\t\\t 0.667 \\t 1.0 \\t 0.8\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 1.0 \\t 0.75 \\t 0.857\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 1.0 \\t 0.667 \\t 0.8\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n-------------------------------------------\\n0.925 \\t\\t 0.967 \\t 0.942 \\t 0.946\\n=================================================================================================\\n                                              s02                                              \\n================================================================================================= \\n\\nAccuracy\\tPre\\tRecall\\tF1\\n0.5 \\t\\t 0.333 \\t 1.0 \\t 0.5\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.5 \\t\\t 0.667 \\t 0.667 \\t 0.667\\n0.75 \\t\\t 1.0 \\t 0.667 \\t 0.8\\n0.5 \\t\\t 1.0 \\t 0.5 \\t 0.667\\n0.75 \\t\\t 1.0 \\t 0.667 \\t 0.8\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 1.0 \\t 0.667 \\t 0.8\\n-------------------------------------------\\n0.775 \\t\\t 0.9 \\t 0.817 \\t 0.823\\n=================================================================================================\\n                                              s03                                              \\n================================================================================================= \\n\\nAccuracy\\tPre\\tRecall\\tF1\\n1.0 \\t\\t 0.0 \\t 0.0 \\t 0.0\\n1.0 \\t\\t 0.0 \\t 0.0 \\t 0.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 1.0 \\t 0.5 \\t 0.667\\n0.75 \\t\\t 0.0 \\t 0.0 \\t 0.0\\n0.75 \\t\\t 0.0 \\t 0.0 \\t 0.0\\n0.75 \\t\\t 0.0 \\t 0.0 \\t 0.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n-------------------------------------------\\n0.9 \\t\\t 0.5 \\t 0.45 \\t 0.467\\n=================================================================================================\\n                                              s04                                              \\n================================================================================================= \\n\\nAccuracy\\tPre\\tRecall\\tF1\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 1.0 \\t 0.667 \\t 0.8\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n1.0 \\t\\t 1.0 \\t 1.0 \\t 1.0\\n0.75 \\t\\t 0.5 \\t 1.0 \\t 0.667\\n-------------------------------------------\\n0.95 \\t\\t 0.95 \\t 0.967 \\t 0.947\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "=================================================================================================\n",
    "                                              s01                                              \n",
    "================================================================================================= \n",
    "\n",
    "Accuracy\tPre\tRecall\tF1\n",
    "0.75 \t\t 0.667 \t 1.0 \t 0.8\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 1.0 \t 0.75 \t 0.857\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 1.0 \t 0.667 \t 0.8\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "-------------------------------------------\n",
    "0.925 \t\t 0.967 \t 0.942 \t 0.946\n",
    "=================================================================================================\n",
    "                                              s02                                              \n",
    "================================================================================================= \n",
    "\n",
    "Accuracy\tPre\tRecall\tF1\n",
    "0.5 \t\t 0.333 \t 1.0 \t 0.5\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.5 \t\t 0.667 \t 0.667 \t 0.667\n",
    "0.75 \t\t 1.0 \t 0.667 \t 0.8\n",
    "0.5 \t\t 1.0 \t 0.5 \t 0.667\n",
    "0.75 \t\t 1.0 \t 0.667 \t 0.8\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 1.0 \t 0.667 \t 0.8\n",
    "-------------------------------------------\n",
    "0.775 \t\t 0.9 \t 0.817 \t 0.823\n",
    "=================================================================================================\n",
    "                                              s03                                              \n",
    "================================================================================================= \n",
    "\n",
    "Accuracy\tPre\tRecall\tF1\n",
    "1.0 \t\t 0.0 \t 0.0 \t 0.0\n",
    "1.0 \t\t 0.0 \t 0.0 \t 0.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 1.0 \t 0.5 \t 0.667\n",
    "0.75 \t\t 0.0 \t 0.0 \t 0.0\n",
    "0.75 \t\t 0.0 \t 0.0 \t 0.0\n",
    "0.75 \t\t 0.0 \t 0.0 \t 0.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "-------------------------------------------\n",
    "0.9 \t\t 0.5 \t 0.45 \t 0.467\n",
    "=================================================================================================\n",
    "                                              s04                                              \n",
    "================================================================================================= \n",
    "\n",
    "Accuracy\tPre\tRecall\tF1\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 1.0 \t 0.667 \t 0.8\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "1.0 \t\t 1.0 \t 1.0 \t 1.0\n",
    "0.75 \t\t 0.5 \t 1.0 \t 0.667\n",
    "-------------------------------------------\n",
    "0.95 \t\t 0.95 \t 0.967 \t 0.947\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "STEP: ** GA based channel + feature selection + SVM classifier for arousal class.ipynb",
   "provenance": [
    {
     "file_id": "1HLyqqmh4klsQ8H-0e4Eq499vAupq5dS0",
     "timestamp": 1639306093118
    },
    {
     "file_id": "1KXk5nWjSgHzZ6ccp66jHRDZI4bJMslHn",
     "timestamp": 1639196338642
    },
    {
     "file_id": "1yUzEFwdmCNH_qb7NPCgLlYElOhT12erL",
     "timestamp": 1634187566670
    },
    {
     "file_id": "1SPeDVHCHi4uFuamkolvaep7nGU7mOyiv",
     "timestamp": 1634152149383
    },
    {
     "file_id": "1aD6aXmoab59Jb7cxRTbtGKDfdiG7ianV",
     "timestamp": 1634151736936
    },
    {
     "file_id": "1luLhv4lQ-SruSeQqeX8bZnYPR-_TYxDk",
     "timestamp": 1634111894346
    },
    {
     "file_id": "11OHLRm15JjC9C-Y-R_LGBacQkwDFduQh",
     "timestamp": 1633972949871
    },
    {
     "file_id": "1qrk7-0VYo258YnzRzG4ztcbrT3zWq-HG",
     "timestamp": 1633964775809
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
